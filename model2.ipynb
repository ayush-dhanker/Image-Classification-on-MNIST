{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPXZbTbY9QpS4LL9v2qtFoU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ayush-dhanker/Image-Classification-on-MNIST/blob/main/model2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIxpPiQQOyIK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# normalizing and transforming\n",
        "transform=transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,),(0.3081,))\n",
        "])\n",
        "\n",
        "# Loading Datasets\n",
        "train_dataset=datasets.MNIST(root='./data',train=True,download=True,transform=transform)\n",
        "test_dataset=datasets.MNIST(root='./data',train=False,download=True,transform=transform)\n",
        "\n",
        "# Data loaders\n",
        "train_loader=DataLoader(train_dataset,batch_size=128,shuffle=True, drop_last=True, num_workers=5)\n",
        "test_loader=DataLoader(test_dataset,batch_size=128,shuffle=False, num_workers=8)"
      ],
      "metadata": {
        "id": "xg3eR8CzPpAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")\n",
        "\n",
        "# building model\n",
        "model= nn.Sequential(\n",
        "      nn.flatten(),\n",
        "      nn.linear(784,512),\n",
        "      nn.ReLU(),\n",
        "      nn.linear(512,128),\n",
        "      nn.ReLU(),\n",
        "      nn.linear(128,10).to(device)\n",
        ")\n",
        "\n",
        "print(\"model = \",model)\n",
        "with torch.no_grad():\n",
        "    print(\"Maximum weight before custom init: \", model[1].weight.max())\n",
        "\n",
        "\n",
        "def glorot_init(layer: nn.Module):\n",
        "    if isinstance(layer, nn.Linear):\n",
        "        nn.init.xavier_uniform_(layer.weight)\n",
        "        nn.init.zeros_(layer.bias)\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    model.apply(glorot_init)\n",
        "    print(\"Maximum weight after custom init\", model[1].weight.max())"
      ],
      "metadata": {
        "id": "YeMNG2PAP-_W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn=nn.CrossEntropyLoss()\n",
        "optimizer=optim.SGD(model.parameters(), lr=0.03)"
      ],
      "metadata": {
        "id": "-dxanqodQ8yB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_model\n",
        "def train_model(\n",
        "    model: nn.Module,\n",
        "    loss_fn: nn.Module,\n",
        "    optimizer: optim.Optimizer,\n",
        "    training_loader: DataLoader,\n",
        "    validation_loader: DataLoader,\n",
        "    n_epochs:int,\n",
        "    verbose:bool=True\n",
        "    ):\n",
        "\n",
        "  train_lem=len(training_loader.dataset)\n",
        "  steps_per_eppoch=train_len/training_loader.batch_size\n",
        "\n",
        "  print(\"Running {} at {} steps per epoch \").format(n_epochs, steps_per_epoch)\n",
        "\n",
        "  train_acc=[]\n",
        "  train_loss=[]\n",
        "  val_acc=[]\n",
        "  val_loss=[]\n",
        "\n",
        "  for epoch in range(n_epochs):\n",
        "    epoch_train_loss=0\n",
        "    epoch_train_acc=0\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  def training_set(\n",
        "      input: torch.tensor,\n",
        "      label: torch.tensor,\n",
        "      model: nn.Module,\n",
        "      loss_fn: nn.Module,\n",
        "      optimizer: optim.Optimizer):\n",
        "\n",
        "    input=input.to(device)\n",
        "    label=label.to(device)\n",
        "    output_batch=model(input)\n",
        "    loss_batch=loss_fn(ouput_batch, label)\n",
        "\n",
        "    loss_batch.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    with torch.no_grad():\n",
        "      batch_acc=accuracy(output_batch,label)\n",
        "    # see loss_batch.item()\n",
        "    return loss_batch,batch_acc\n",
        "\n",
        "\n",
        "\n",
        "  def evaluate(\n",
        "      model:nn.Module,\n",
        "      dataloader:DataLoader,\n",
        "      loss_fn:nn.Module):\n",
        "    model.eval()\n",
        "    size=len(dataloader.dataset)\n",
        "    num_batches=len(dataloader)\n",
        "    loss=0\n",
        "    correct=0\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for input,label in dataloader:\n",
        "        input=input.to(device)\n",
        "        label=label.to(device)\n",
        "        prediction=model(input)\n",
        "        val_loss=loss_fn(prediction,label)\n",
        "        correct += (prediction.armax(axis=1)==label).type(torch.float).sum().item()\n",
        "\n",
        "    loss/=num_batches\n",
        "    val_accuracy=correct/size\n",
        "    return loss, val_accuracy\n",
        "\n",
        "  def accuracy(labels:torch.tensor,\n",
        "               outputs:torch.tensor)=>torch.tensor:\n",
        "               predictions=torch.argmac(outputs,axis=-1)\n",
        "               matches=labels==predictions\n",
        "               return matches.float().mean()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "L_0XP60AOrhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = train_model(model, loss_fn, optimizer, train_dataloader, test_dataloader, n_epochs=25)"
      ],
      "metadata": {
        "id": "TA6a9PLrQ76t"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}